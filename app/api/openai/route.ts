// /app/api/openai/route.ts

"use server";

import { NextResponse } from "next/server";
import { z } from "zod";
import OpenAI from "openai";
import { generateFilledPrompts } from "@/utils/fillPrompts";

const requestBodySchema = z.object({
  prompt: z.string(),
  userId: z.string(),
  options: z
    .object({
      categorized: z.boolean().optional(),
      platform: z.string().optional(),
      format: z.string().optional(),
      tone: z.string().optional(),
      audience: z.string().optional(),
      count: z.number().optional(),
    })
    .optional(),
});

const DEFAULT_NON_CATEGORIZED_COUNT = 5;
const openai = new OpenAI();

export async function POST(req: Request) {
  try {
    const json = await req.json();
    const parsed = requestBodySchema.safeParse(json);

    if (!parsed.success) {
      return NextResponse.json(
        { success: false, errors: parsed.error.format() },
        { status: 400 }
      );
    }

    const { prompt, userId, options } = parsed.data;
    const isCategorized = options?.categorized ?? false;
    const ideaCount = options?.count ?? DEFAULT_NON_CATEGORIZED_COUNT;

    const filledPrompts = await generateFilledPrompts(userId);
    if ("error" in filledPrompts) {
      return NextResponse.json(
        { success: false, error: filledPrompts.error },
        { status: 500 }
      );
    }

    const systemMessage = filledPrompts.blocks
      .map((blk) => blk.prompt.trim())
      .join("\n\n");

    const systemMessageWithInstructions = `
${systemMessage}

VocÃª Ã© um assistente que **sempre retorna apenas JSON vÃ¡lido com aspas duplas ASCII (")**. NÃ£o adicione texto fora do JSON.

Formato esperado da resposta:
{
  "ideas": [ ... ],
  "categories": [ ... ]
}

Para cada ideia de conteÃºdo, inclua:
- id
- title
- description
- context
- steps (em ordem)
- examples
- variations
- platform
- format
- tags
- estimatedEngagement
- difficulty
- timeToCreate
- bestTimeToPost
- targetAudience
- isFavorite (sempre false)

NUNCA inclua explicaÃ§Ãµes fora do JSON.
`.trim();

    let userPrompt = `
Com base neste input do usuÃ¡rio: "${prompt}", gere exatamente ${ideaCount} ideias de conteÃºdo altamente detalhadas com base nas preferÃªncias do negÃ³cio.

âš™ï¸ FASE 1 â€“ DNA VIRALGEN (CriaÃ§Ã£o EstratÃ©gica)

Cada conteÃºdo deve seguir exatamente esta sequÃªncia lÃ³gica:

ğŸ“ [fase1.1] GANCHO SUPREMO â€“ O scroll killer

Objetivo: parar o dedo em atÃ© 3s.

Use gatilhos como: curiosidade, escassez, status, medo, antecipaÃ§Ã£o.

Ex: â€œ90% das dietas fracassam. Descubra o motivo real.â€

ğŸ“ [fase1.2] CHOQUE DE REALIDADE â€“ Confronto cognitivo

Objetivo: gerar revolta, consciÃªncia ou alerta mental.

Ex: â€œVocÃª estÃ¡ envelhecendo 20% mais rÃ¡pido por nÃ£o fazer isso.â€

ğŸ“ [fase1.3] STORYTELLING + CONTEXTO â€“ ConexÃ£o emocional

Objetivo: ativar identificaÃ§Ã£o e vÃ­nculo narrativo.

Ex: â€œEm 2018, um brasileiro transformou R$2 mil em R$2 milhÃµes.â€

ğŸ“ [fase1.4] ENTREGA DE VALOR 1 â€“ Parte Oculta

Entregue valor real, mas guarde uma peÃ§a para depois.

Ex: â€œPasso 1: Identifique um produto com demanda oculta...â€

ğŸ“ [fase1.5] CTA DUPLO + BENEFÃCIO REAL

Regra: 2 aÃ§Ãµes obrigatÃ³rias + uma recompensa ou benefÃ­cio.

Ex: â€œSiga + comente â€˜QUEROâ€™ para receber o checklist oculto.â€

ğŸ“ [fase1.6] ENTREGA DE VALOR 2 â€“ Parte Revelada

Mostre a peÃ§a final, valide autoridade, conclua com impacto.

Ex: â€œOs 3 hacks que aumentaram meus leads em 400%.â€

ğŸ“ [fase1.7] CALL TO BASE (CTB 2.0)

Leve o pÃºblico para ambientes prÃ³prios e seguros.

Ex: â€œAcesse a lista secreta pelo link da bio.â€

ğŸ“ [fase1.8] CLIFFHANGER SUPREMO â€“ Continuidade

Ex: â€œAmanhÃ£ eu revelo como vocÃª pode aplicar isso em 24h.â€


A resposta deve estar em JSON puro e vÃ¡lido.
`.trim();

    if (options?.platform) userPrompt += `\nPlataforma: ${options.platform}`;
    if (options?.format) userPrompt += `\nFormato: ${options.format}`;
    if (options?.tone) userPrompt += `\nTom: ${options.tone}`;
    if (options?.audience) userPrompt += `\nPÃºblico-alvo: ${options.audience}`;

    const chatResponse = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: systemMessageWithInstructions },
        { role: "user", content: userPrompt },
      ],
      temperature: 1,
      max_tokens: 3000,
    });

    const rawText = chatResponse.choices?.[0]?.message?.content || "";
    const cleaned = rawText.replace(/[â€œâ€]/g, '"').replace(/â€˜|â€™/g, "'");
    console.log("Resposta da OpenAI:", cleaned);

    let parsedJson;
    try {
      parsedJson = JSON.parse(cleaned);
    } catch (err) {
      return NextResponse.json(
        { success: false, error: "Resposta invÃ¡lida da OpenAI." },
        { status: 500 }
      );
    }

    return NextResponse.json({
      success: true,
      data: isCategorized
        ? { categories: parsedJson.categories || [] }
        : { ideas: parsedJson.ideas || [] },
    });
  } catch (err: any) {
    return NextResponse.json(
      { success: false, error: err.message || "Erro desconhecido" },
      { status: 500 }
    );
  }
}
